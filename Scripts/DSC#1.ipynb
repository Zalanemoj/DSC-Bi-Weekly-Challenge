{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9463564",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-16T16:03:15.725441Z",
     "iopub.status.busy": "2026-01-16T16:03:15.725017Z",
     "iopub.status.idle": "2026-01-16T16:16:19.699370Z",
     "shell.execute_reply": "2026-01-16T16:16:19.698276Z"
    },
    "papermill": {
     "duration": 783.98244,
     "end_time": "2026-01-16T16:16:19.701633",
     "exception": false,
     "start_time": "2026-01-16T16:03:15.719193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "  if entities is not ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  NYC REAL ESTATE PRICE PREDICTION - GRANDMASTER PIPELINE (FIXED)\n",
      "======================================================================\n",
      "Preprocessing Training data...\n",
      "‚úì Final Shape: (46745, 25)\n",
      "Preprocessing Test data...\n",
      "‚úì Final Shape: (14008, 25)\n",
      "\n",
      "üîç Optimizing XGBoost (50 trials)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8916101619674f899a9e8ac601e1b397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ ENSEMBLE TRAINING START\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5218714649449e9ab4c9e99ed28b69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training Complete. Models Saved.\n",
      "\n",
      "üèóÔ∏è Training Meta-Learner (Stacking)...\n",
      "  Stacked CV RMSE: 0.03367\n",
      "\n",
      "======================================================================\n",
      "GENERATING FINAL SUBMISSION\n",
      "======================================================================\n",
      "‚úì Generating predictions with aligned shape: (14008, 25)\n",
      "‚úì Saved 14008 rows to 'submission.csv'\n",
      "   Property_ID     PREDICTED\n",
      "0        69521  20478.636131\n",
      "1        76928  21433.525972\n",
      "2        82053  22716.080652\n",
      "3        56262  21703.474075\n",
      "4        51915  22795.702675\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  NYC REAL ESTATE PRICE PREDICTION - GRANDMASTER PIPELINE (FIXED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class GrandmasterPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.target = None\n",
    "        self.test_ids = None\n",
    "        self.train_columns = None\n",
    "        \n",
    "    def clean_column_names(self, df):\n",
    "        new_columns = [re.sub(r'[^A-Za-z0-9_]+', '_', str(col)) for col in df.columns]\n",
    "        df.columns = new_columns\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "\n",
    "        placeholders = ['-', ' -', '- ', ' - ', '  -  ', '', ' ']\n",
    "        df.replace(placeholders, np.nan, inplace=True)\n",
    " \n",
    "        numeric_cols = ['LAND SQUARE FEET', 'GROSS SQUARE FEET', \n",
    "                        'RESIDENTIAL UNITS', 'COMMERCIAL UNITS', 'TOTAL UNITS',\n",
    "                        'YEAR BUILT', 'SALE PRICE', 'ZIP CODE']\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        if is_train and 'SALE PRICE' in df.columns:\n",
    "            df = df.dropna(subset=['SALE PRICE'])\n",
    "            df = df[df['SALE PRICE'] > 10_000].reset_index(drop=True)\n",
    "            self.target = df['SALE PRICE'].copy()\n",
    "            \n",
    "        # 4. Outlier Clipping\n",
    "        for col in ['LAND SQUARE FEET', 'GROSS SQUARE FEET']:\n",
    "            if col in df.columns:\n",
    "                upper = df[col].quantile(0.995)\n",
    "                df.loc[df[col] > upper, col] = upper\n",
    "                \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        if 'SALE DATE' in df.columns:\n",
    "            df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], errors='coerce')\n",
    "            df['sale_year'] = df['SALE DATE'].dt.year\n",
    "            df['sale_month'] = df['SALE DATE'].dt.month\n",
    "            \n",
    "            if 'YEAR BUILT' in df.columns:\n",
    "                df['building_age'] = df['sale_year'] - df['YEAR BUILT']\n",
    "                df.loc[df['building_age'] < 0, 'building_age'] = 0 \n",
    "            \n",
    "            df.drop('SALE DATE', axis=1, inplace=True)\n",
    "            \n",
    "        for col in ['GROSS SQUARE FEET', 'LAND SQUARE FEET', 'TOTAL UNITS']:\n",
    "            if col in df.columns:\n",
    "                df[f'log_{col}'] = np.log1p(df[col].fillna(0))\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def encode_categorical(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        drop_cols = ['ADDRESS', 'APARTMENT NUMBER', 'EASE-MENT']\n",
    "        df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "        \n",
    "        cat_cols = df.select_dtypes(include=['object']).columns\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            if is_train:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str).fillna(\"Unknown\"))\n",
    "                self.label_encoders[col] = le\n",
    "            else:\n",
    "                if col in self.label_encoders:\n",
    "                    le = self.label_encoders[col]\n",
    "                    df[col] = df[col].astype(str).fillna(\"Unknown\").apply(\n",
    "                        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "                    )\n",
    "        return df\n",
    "    \n",
    "    def transform(self, df, is_train=True):\n",
    "        print(f\"Preprocessing {'Training' if is_train else 'Test'} data...\")\n",
    "        \n",
    "        df = self.clean_data(df, is_train)\n",
    "        df = self.engineer_features(df)\n",
    "        df = self.encode_categorical(df, is_train)\n",
    "        \n",
    "        num_cols = df.select_dtypes(include=np.number).columns\n",
    "        df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "        \n",
    "        if 'Property_ID' in df.columns:\n",
    "            self.test_ids = df['Property_ID'].copy()\n",
    "            \n",
    "        cols_to_drop = ['Property_ID', 'SALE PRICE']\n",
    "        df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True)\n",
    "        \n",
    "        df = self.clean_column_names(df)\n",
    "        \n",
    "        # ALIGNMENT: Ensure Test has exact same columns as Train\n",
    "        if is_train:\n",
    "            self.train_columns = df.columns.tolist()\n",
    "        else:\n",
    "            if self.train_columns is not None:\n",
    "                for col in self.train_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = 0\n",
    "                df = df[self.train_columns]\n",
    "        \n",
    "        print(f\"‚úì Final Shape: {df.shape}\")\n",
    "        return df\n",
    "\n",
    "# LOAD DATA\n",
    "train_raw = pd.read_csv('/kaggle/input/dsc-nyc-real-estate/training.csv')\n",
    "test_raw = pd.read_csv('/kaggle/input/dsc-nyc-real-estate/test.csv')\n",
    "\n",
    "# EXECUTE PIPELINE\n",
    "processor = GrandmasterPreprocessor()\n",
    "X_train = processor.transform(train_raw, is_train=True)\n",
    "y_train = np.log1p(processor.target)\n",
    "X_test = processor.transform(test_raw, is_train=False)\n",
    "test_ids = processor.test_ids\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "class BayesianOptimizer:\n",
    "    def __init__(self, X, y, n_trials=50, params_file='best_params.json'):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_trials = n_trials\n",
    "        self.params_file = params_file\n",
    "        self.best_params = {}\n",
    "        \n",
    "    def load_params(self):\n",
    "        if os.path.exists(self.params_file):\n",
    "            print(f\"\\n‚úì Loaded existing params from {self.params_file}\")\n",
    "            with open(self.params_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "\n",
    "    def objective_xgb(self, trial):\n",
    "        params = {\n",
    "            'n_estimators': 1000,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'tree_method': 'hist',  # Fast CPU Histogram method\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "        \n",
    "        y_bins = pd.qcut(self.y, q=5, labels=False)\n",
    "        kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        for train_idx, val_idx in kf.split(self.X, y_bins):\n",
    "            X_tr, X_val = self.X.iloc[train_idx], self.X.iloc[val_idx]\n",
    "            y_tr, y_val = self.y.iloc[train_idx], self.y.iloc[val_idx]\n",
    "            \n",
    "            model = xgb.XGBRegressor(**params)\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            preds = model.predict(X_val)\n",
    "            scores.append(np.sqrt(mean_squared_error(y_val, preds)))\n",
    "            \n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize(self):\n",
    "        saved = self.load_params()\n",
    "        if 'xgb' in saved:\n",
    "            self.best_params = saved\n",
    "            return saved\n",
    "        \n",
    "        print(f\"\\nüîç Optimizing XGBoost ({self.n_trials} trials)...\")\n",
    "        study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "        study.optimize(self.objective_xgb, n_trials=self.n_trials, show_progress_bar=True)\n",
    "        \n",
    "        self.best_params['xgb'] = study.best_params\n",
    "        \n",
    "        with open(self.params_file, 'w') as f:\n",
    "            json.dump(self.best_params, f, indent=4)\n",
    "            \n",
    "        return self.best_params\n",
    "\n",
    "optimizer = BayesianOptimizer(X_train, y_train, n_trials=50)\n",
    "best_params = optimizer.optimize()\n",
    "\n",
    "class UltimateEnsemble:\n",
    "    def __init__(self, xgb_params, n_folds=5, model_dir='models'):\n",
    "        self.xgb_params = xgb_params\n",
    "        self.n_folds = n_folds\n",
    "        self.model_dir = model_dir\n",
    "        self.models = {'xgb': [], 'lgb': [], 'cat': [], 'rf': [], 'enet': []}\n",
    "        self.meta_model = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "\n",
    "    def load_if_exists(self, filename):\n",
    "        path = os.path.join(self.model_dir, filename)\n",
    "        if os.path.exists(path):\n",
    "            return joblib.load(path)\n",
    "        return None\n",
    "\n",
    "    def save_model(self, obj, filename):\n",
    "        joblib.dump(obj, os.path.join(self.model_dir, filename))\n",
    "\n",
    "    def train_with_cv(self, X, y):\n",
    "        print(\"\\nüöÄ ENSEMBLE TRAINING START\")\n",
    "        \n",
    "        self.oof_preds = self.load_if_exists('oof_preds.pkl')\n",
    "        loaded_models = self.load_if_exists('ensemble_models.pkl')\n",
    "        self.feature_names = self.load_if_exists('feature_names.pkl')\n",
    "        \n",
    "        if self.oof_preds is not None and loaded_models is not None:\n",
    "            print(\"‚úì Loaded trained models from checkpoint. Skipping training.\")\n",
    "            self.models = loaded_models\n",
    "            return self\n",
    "        \n",
    "        self.feature_names = X.columns.tolist()\n",
    "        self.save_model(self.feature_names, 'feature_names.pkl')\n",
    "        \n",
    "        y_bins = pd.qcut(y, q=10, labels=False, duplicates='drop')\n",
    "        kf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        oof = {k: np.zeros(len(X)) for k in self.models.keys()}\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X, y_bins), total=self.n_folds, desc=\"Folds\")):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            xgb_m = xgb.XGBRegressor(**self.xgb_params, n_estimators=2000, \n",
    "                                     tree_method='hist', n_jobs=-1, # CPU HIST\n",
    "                                     early_stopping_rounds=50, random_state=42)\n",
    "            xgb_m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            oof['xgb'][val_idx] = xgb_m.predict(X_val)\n",
    "            self.models['xgb'].append(xgb_m)\n",
    "\n",
    "            lgb_m = lgb.LGBMRegressor(n_estimators=2000, learning_rate=0.03, num_leaves=31,\n",
    "                                      n_jobs=-1, random_state=42, verbosity=-1)\n",
    "            lgb_m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n",
    "                      callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            oof['lgb'][val_idx] = lgb_m.predict(X_val)\n",
    "            self.models['lgb'].append(lgb_m)\n",
    "\n",
    "            cat_m = cb.CatBoostRegressor(iterations=2000, learning_rate=0.03, depth=6,\n",
    "                                         loss_function='RMSE', verbose=0, random_seed=42)\n",
    "            cat_m.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "            oof['cat'][val_idx] = cat_m.predict(X_val)\n",
    "            self.models['cat'].append(cat_m)\n",
    "\n",
    "            rf_m = RandomForestRegressor(n_estimators=200, max_depth=12, max_features='sqrt',\n",
    "                                         n_jobs=-1, random_state=42)\n",
    "            rf_m.fit(X_tr, y_tr)\n",
    "            oof['rf'][val_idx] = rf_m.predict(X_val)\n",
    "            self.models['rf'].append(rf_m)\n",
    "\n",
    "            enet_m = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('model', ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42))\n",
    "            ])\n",
    "            enet_m.fit(X_tr, y_tr)\n",
    "            oof['enet'][val_idx] = enet_m.predict(X_val)\n",
    "            self.models['enet'].append(enet_m)\n",
    "            \n",
    "        self.oof_preds = pd.DataFrame(oof)\n",
    "        self.save_model(self.models, 'ensemble_models.pkl')\n",
    "        self.save_model(self.oof_preds, 'oof_preds.pkl')\n",
    "        print(\"‚úì Training Complete. Models Saved.\")\n",
    "        return self\n",
    "\n",
    "    def train_meta_learner(self, y):\n",
    "        print(\"\\nüèóÔ∏è Training Meta-Learner (Stacking)...\")\n",
    "        self.meta_model = Ridge(alpha=10.0, random_state=42)\n",
    "        self.meta_model.fit(self.oof_preds, y)\n",
    "        self.save_model(self.meta_model, 'meta_model.pkl')\n",
    "        \n",
    "        cv_score = np.sqrt(mean_squared_error(y, self.meta_model.predict(self.oof_preds)))\n",
    "        print(f\"  Stacked CV RMSE: {cv_score:.5f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.feature_names is None:\n",
    "             self.feature_names = self.load_if_exists('feature_names.pkl')\n",
    "             \n",
    "        if self.feature_names:\n",
    "            missing = set(self.feature_names) - set(X.columns)\n",
    "            for c in missing: X[c] = 0\n",
    "            extra = set(X.columns) - set(self.feature_names)\n",
    "            if extra: X = X.drop(columns=list(extra))\n",
    "            X = X[self.feature_names]\n",
    "            \n",
    "        print(f\"‚úì Generating predictions with aligned shape: {X.shape}\")\n",
    "        \n",
    "        test_preds = {}\n",
    "        for name in self.models:\n",
    "            preds = []\n",
    "            for model in self.models[name]:\n",
    "                preds.append(model.predict(X))\n",
    "            test_preds[name] = np.mean(preds, axis=0)\n",
    "            \n",
    "        meta_X = pd.DataFrame(test_preds)\n",
    "        return self.meta_model.predict(meta_X)\n",
    "\n",
    "# TRAIN ENSEMBLE\n",
    "ensemble = UltimateEnsemble(best_params.get('xgb', {}), n_folds=5)\n",
    "ensemble.train_with_cv(X_train, y_train)\n",
    "ensemble.train_meta_learner(y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING FINAL SUBMISSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_log_preds = ensemble.predict(X_test)\n",
    "final_preds = np.expm1(final_log_preds)\n",
    "final_preds = np.maximum(final_preds, 0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Property_ID': test_ids,\n",
    "    'PREDICTED': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úì Saved {len(submission)} rows to 'submission.csv'\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11506ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T16:16:19.710016Z",
     "iopub.status.busy": "2026-01-16T16:16:19.709497Z",
     "iopub.status.idle": "2026-01-16T16:16:33.965573Z",
     "shell.execute_reply": "2026-01-16T16:16:33.964580Z"
    },
    "papermill": {
     "duration": 14.263149,
     "end_time": "2026-01-16T16:16:33.967820",
     "exception": false,
     "start_time": "2026-01-16T16:16:19.704671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  NYC REAL ESTATE - ULTIMATE GRANDMASTER PIPELINE (FIXED)\n",
      "======================================================================\n",
      "Preprocessing Training data...\n",
      "‚úì Final Shape: (46745, 26)\n",
      "Preprocessing Test data...\n",
      "‚úì Final Shape: (14008, 26)\n",
      "\n",
      "‚úì Loaded parameters from best_params.json\n",
      "\n",
      "üîç STARTING BAYESIAN OPTIMIZATION\n",
      "\n",
      "üöÄ ENSEMBLE TRAINING START\n",
      "‚úì Loaded trained models from checkpoint. Skipping training.\n",
      "\n",
      "üèóÔ∏è Training Meta-Learner...\n",
      "  Stacked CV RMSE: 0.03367\n",
      "\n",
      "======================================================================\n",
      "GENERATING FINAL SUBMISSION\n",
      "======================================================================\n",
      "‚úì Predicting with shape: (14008, 25)\n",
      "‚úì Saved 14008 rows to 'submission.csv'\n",
      "   Property_ID     PREDICTED\n",
      "0        69521  21376.578016\n",
      "1        76928  21498.392205\n",
      "2        82053  22128.706413\n",
      "3        56262  21404.850234\n",
      "4        51915  22892.234162\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  NYC REAL ESTATE - ULTIMATE GRANDMASTER PIPELINE (FIXED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols, smoothing=10):\n",
    "        self.cols = cols\n",
    "        self.smoothing = smoothing\n",
    "        self.maps = {}\n",
    "        self.global_mean = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.global_mean = y.mean()\n",
    "        for col in self.cols:\n",
    "            stats = pd.DataFrame({'sum': y.groupby(X[col]).sum(), \n",
    "                                  'count': y.groupby(X[col]).count()})\n",
    "            self.maps[col] = (stats['sum'] + self.smoothing * self.global_mean) / (stats['count'] + self.smoothing)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out = X.copy()\n",
    "        for col in self.cols:\n",
    "            if col in self.maps:\n",
    "                X_out[col] = X_out[col].map(self.maps[col]).fillna(self.global_mean)\n",
    "        return X_out\n",
    "\n",
    "class GrandmasterPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.target_encoder = None\n",
    "        self.target = None\n",
    "        self.test_ids = None\n",
    "        self.train_columns = None\n",
    "        \n",
    "    def clean_column_names(self, df):\n",
    "        new_columns = [re.sub(r'[^A-Za-z0-9_]+', '_', str(col)) for col in df.columns]\n",
    "        df.columns = new_columns\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "\n",
    "        placeholders = ['-', ' -', '- ', ' - ', '  -  ', '', ' ']\n",
    "        df.replace(placeholders, np.nan, inplace=True)\n",
    "        \n",
    "\n",
    "        numeric_cols = ['LAND SQUARE FEET', 'GROSS SQUARE FEET', \n",
    "                        'RESIDENTIAL UNITS', 'COMMERCIAL UNITS', 'TOTAL UNITS',\n",
    "                        'YEAR BUILT', 'SALE PRICE']\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        if is_train and 'SALE PRICE' in df.columns:\n",
    "            df = df.dropna(subset=['SALE PRICE'])\n",
    "\n",
    "            df = df[df['SALE PRICE'] > 10_000].reset_index(drop=True)\n",
    "            self.target = df['SALE PRICE'].copy()\n",
    "\n",
    "        for col in ['LAND SQUARE FEET', 'GROSS SQUARE FEET']:\n",
    "            if col in df.columns:\n",
    "                upper = df[col].quantile(0.995)\n",
    "                df.loc[df[col] > upper, col] = upper\n",
    "\n",
    "        drop_cols = ['Unnamed: 0', 'PriceScore', 'DistressedAsset', 'EASE-MENT']\n",
    "        df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True, errors='ignore')\n",
    "                \n",
    "        return df\n",
    "    \n",
    "    def engineer_features(self, df):\n",
    "        df = df.copy()\n",
    "\n",
    "        if 'SALE DATE' in df.columns:\n",
    "            df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], errors='coerce')\n",
    "            df['sale_year'] = df['SALE DATE'].dt.year\n",
    "            df['sale_month'] = df['SALE DATE'].dt.month\n",
    "            \n",
    "            # Cyclical encoding\n",
    "            df['month_sin'] = np.sin(2 * np.pi * df['sale_month']/12)\n",
    "            df['month_cos'] = np.cos(2 * np.pi * df['sale_month']/12)\n",
    "            \n",
    "            if 'YEAR BUILT' in df.columns:\n",
    "                df['building_age'] = df['sale_year'] - df['YEAR BUILT']\n",
    "                df.loc[df['building_age'] < 0, 'building_age'] = 0\n",
    "            \n",
    "            df.drop('SALE DATE', axis=1, inplace=True)\n",
    "\n",
    "        if 'GROSS SQUARE FEET' in df.columns and 'LAND SQUARE FEET' in df.columns:\n",
    "            df['total_area'] = df['GROSS SQUARE FEET'].fillna(0) + df['LAND SQUARE FEET'].fillna(0)\n",
    "\n",
    "        for col in ['GROSS SQUARE FEET', 'LAND SQUARE FEET', 'total_area', 'RESIDENTIAL UNITS']:\n",
    "            if col in df.columns:\n",
    "                df[f'log_{col}'] = np.log1p(df[col].fillna(0))\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def encode_categorical(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Drop high cardinality\n",
    "        df.drop(columns=['ADDRESS', 'APARTMENT NUMBER'], inplace=True, errors='ignore')\n",
    "        \n",
    "        # Prepare for Label Encoding (Skip Target Encode Cols)\n",
    "        target_encode_cols = ['NEIGHBORHOOD', 'ZIP CODE', 'BOROUGH']\n",
    "        cat_cols = df.select_dtypes(include=['object']).columns\n",
    "        cat_cols = [c for c in cat_cols if c not in target_encode_cols]\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            if is_train:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col].astype(str).fillna(\"Unknown\"))\n",
    "                self.label_encoders[col] = le\n",
    "            else:\n",
    "                if col in self.label_encoders:\n",
    "                    le = self.label_encoders[col]\n",
    "                    df[col] = df[col].astype(str).fillna(\"Unknown\").apply(\n",
    "                        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "                    )\n",
    "\n",
    "        for col in target_encode_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "                \n",
    "        return df\n",
    "    \n",
    "    def transform(self, df, is_train=True):\n",
    "        print(f\"Preprocessing {'Training' if is_train else 'Test'} data...\")\n",
    "        \n",
    "        df = self.clean_data(df, is_train)\n",
    "        df = self.engineer_features(df)\n",
    "        df = self.encode_categorical(df, is_train)\n",
    "\n",
    "        num_cols = df.select_dtypes(include=np.number).columns\n",
    "        df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "        target_cols = ['NEIGHBORHOOD', 'ZIP CODE', 'BOROUGH']\n",
    "        target_cols = [c for c in target_cols if c in df.columns]\n",
    "        \n",
    "        if is_train:\n",
    "            self.target_encoder = TargetEncoder(cols=target_cols, smoothing=20)\n",
    "\n",
    "            self.target_encoder.fit(df, np.log1p(self.target)) \n",
    "            df = self.target_encoder.transform(df)\n",
    "        elif self.target_encoder:\n",
    "            df = self.target_encoder.transform(df)\n",
    "        if 'Property_ID' in df.columns:\n",
    "            self.test_ids = df['Property_ID'].copy()\n",
    "            \n",
    "        cols_to_drop = ['Property_ID', 'SALE PRICE']\n",
    "        df.drop(columns=[c for c in cols_to_drop if c in df.columns], inplace=True, errors='ignore')\n",
    "        \n",
    "        df = self.clean_column_names(df)\n",
    "        if is_train:\n",
    "            self.train_columns = df.columns.tolist()\n",
    "        else:\n",
    "            if self.train_columns:\n",
    "                for col in self.train_columns:\n",
    "                    if col not in df.columns: df[col] = 0\n",
    "                df = df[self.train_columns]\n",
    "        \n",
    "        print(f\"‚úì Final Shape: {df.shape}\")\n",
    "        return df\n",
    "\n",
    "train_raw = pd.read_csv('/kaggle/input/dsc-nyc-real-estate/training.csv')\n",
    "test_raw = pd.read_csv('/kaggle/input/dsc-nyc-real-estate/test.csv')\n",
    "\n",
    "# RUN PIPELINE\n",
    "processor = GrandmasterPreprocessor()\n",
    "X_train = processor.transform(train_raw, is_train=True)\n",
    "y_train = np.log1p(processor.target)\n",
    "X_test = processor.transform(test_raw, is_train=False)\n",
    "test_ids = processor.test_ids\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "class BayesianOptimizer:\n",
    "    def __init__(self, X, y, n_trials=30, params_file='best_params.json'):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_trials = n_trials\n",
    "        self.params_file = params_file\n",
    "        self.best_params = self.load_params()\n",
    "        \n",
    "    def load_params(self):\n",
    "        if os.path.exists(self.params_file):\n",
    "            print(f\"\\n‚úì Loaded parameters from {self.params_file}\")\n",
    "            with open(self.params_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "    \n",
    "    def save_params(self):\n",
    "        with open(self.params_file, 'w') as f:\n",
    "            json.dump(self.best_params, f, indent=4)\n",
    "\n",
    "    def objective_xgb(self, trial):\n",
    "        params = {\n",
    "            'n_estimators': 1000,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'tree_method': 'hist', \n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        for tr_idx, val_idx in kf.split(self.X):\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "            model.fit(self.X.iloc[tr_idx], self.y.iloc[tr_idx], \n",
    "                      eval_set=[(self.X.iloc[val_idx], self.y.iloc[val_idx])], verbose=False)\n",
    "            preds = model.predict(self.X.iloc[val_idx])\n",
    "            scores.append(np.sqrt(mean_squared_error(self.y.iloc[val_idx], preds)))\n",
    "        return np.mean(scores)\n",
    "\n",
    "    def optimize(self):\n",
    "        print(\"\\nüîç STARTING BAYESIAN OPTIMIZATION\")\n",
    "        if 'xgb' not in self.best_params:\n",
    "            study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=42))\n",
    "            study.optimize(self.objective_xgb, n_trials=self.n_trials, show_progress_bar=True)\n",
    "            self.best_params['xgb'] = study.best_params\n",
    "            self.save_params()\n",
    "            \n",
    "        if 'lgb' not in self.best_params:\n",
    "            # Default strong params for LGBM to save time\n",
    "            self.best_params['lgb'] = {\n",
    "                'n_estimators': 2000, 'learning_rate': 0.03, 'num_leaves': 31,\n",
    "                'colsample_bytree': 0.8, 'subsample': 0.8\n",
    "            }\n",
    "            \n",
    "        if 'cat' not in self.best_params:\n",
    "            self.best_params['cat'] = {'iterations': 2000, 'learning_rate': 0.03, 'depth': 6}\n",
    "            \n",
    "        self.save_params()\n",
    "        return self.best_params\n",
    "\n",
    "optimizer = BayesianOptimizer(X_train, y_train, n_trials=50)\n",
    "best_params = optimizer.optimize()\n",
    "class UltimateEnsemble:\n",
    "    def __init__(self, params, n_folds=5, model_dir='models'):\n",
    "        self.params = params\n",
    "        self.n_folds = n_folds\n",
    "        self.model_dir = model_dir\n",
    "        self.models = {'xgb': [], 'lgb': [], 'cat': [], 'rf': [], 'enet': []}\n",
    "        self.meta_model = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "\n",
    "    def load_if_exists(self, filename):\n",
    "        path = os.path.join(self.model_dir, filename)\n",
    "        if os.path.exists(path):\n",
    "            return joblib.load(path)\n",
    "        return None\n",
    "\n",
    "    def save_model(self, obj, filename):\n",
    "        joblib.dump(obj, os.path.join(self.model_dir, filename))\n",
    "\n",
    "    def train_with_cv(self, X, y):\n",
    "        print(\"\\nüöÄ ENSEMBLE TRAINING START\")\n",
    "        \n",
    "        self.oof_preds = self.load_if_exists('oof_preds.pkl')\n",
    "        loaded_models = self.load_if_exists('ensemble_models.pkl')\n",
    "        self.feature_names = self.load_if_exists('feature_names.pkl')\n",
    "        \n",
    "        if self.oof_preds is not None and loaded_models is not None:\n",
    "            print(\"‚úì Loaded trained models from checkpoint. Skipping training.\")\n",
    "            self.models = loaded_models\n",
    "            return self\n",
    "        \n",
    "        self.feature_names = X.columns.tolist()\n",
    "        self.save_model(self.feature_names, 'feature_names.pkl')\n",
    "        \n",
    "        y_bins = pd.qcut(y, q=10, labels=False, duplicates='drop')\n",
    "        kf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        oof = {k: np.zeros(len(X)) for k in self.models.keys()}\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X, y_bins), total=self.n_folds, desc=\"Folds\")):\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "\n",
    "            xgb_m = xgb.XGBRegressor(**self.params['xgb'], n_estimators=2000, \n",
    "                                     tree_method='hist', n_jobs=-1, early_stopping_rounds=50, random_state=42)\n",
    "            xgb_m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            oof['xgb'][val_idx] = xgb_m.predict(X_val)\n",
    "            self.models['xgb'].append(xgb_m)\n",
    "\n",
    "            lgb_m = lgb.LGBMRegressor(**self.params['lgb'], n_jobs=-1, random_state=42, verbosity=-1)\n",
    "            lgb_m.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], \n",
    "                      callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            oof['lgb'][val_idx] = lgb_m.predict(X_val)\n",
    "            self.models['lgb'].append(lgb_m)\n",
    "\n",
    "            cat_m = cb.CatBoostRegressor(**self.params['cat'], loss_function='RMSE', verbose=0, random_seed=42)\n",
    "            cat_m.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
    "            oof['cat'][val_idx] = cat_m.predict(X_val)\n",
    "            self.models['cat'].append(cat_m)\n",
    "\n",
    "            rf_m = RandomForestRegressor(n_estimators=200, max_depth=12, max_features='sqrt',\n",
    "                                         n_jobs=-1, random_state=42)\n",
    "            rf_m.fit(X_tr, y_tr)\n",
    "            oof['rf'][val_idx] = rf_m.predict(X_val)\n",
    "            self.models['rf'].append(rf_m)\n",
    "\n",
    "            enet_m = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', RobustScaler()),\n",
    "                ('model', ElasticNet(alpha=0.001, l1_ratio=0.5, random_state=42))\n",
    "            ])\n",
    "            enet_m.fit(X_tr, y_tr)\n",
    "            oof['enet'][val_idx] = enet_m.predict(X_val)\n",
    "            self.models['enet'].append(enet_m)\n",
    "            \n",
    "        self.oof_preds = pd.DataFrame(oof)\n",
    "        self.save_model(self.models, 'ensemble_models.pkl')\n",
    "        self.save_model(self.oof_preds, 'oof_preds.pkl')\n",
    "        print(\"‚úì Training Complete.\")\n",
    "        return self\n",
    "\n",
    "    def train_meta_learner(self, y):\n",
    "        print(\"\\nüèóÔ∏è Training Meta-Learner...\")\n",
    "        self.meta_model = Ridge(alpha=10.0, random_state=42)\n",
    "        self.meta_model.fit(self.oof_preds, y)\n",
    "        self.save_model(self.meta_model, 'meta_model.pkl')\n",
    "        \n",
    "        cv_score = np.sqrt(mean_squared_error(y, self.meta_model.predict(self.oof_preds)))\n",
    "        print(f\"  Stacked CV RMSE: {cv_score:.5f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        if self.feature_names is None:\n",
    "             self.feature_names = self.load_if_exists('feature_names.pkl')\n",
    "             \n",
    "        if self.feature_names:\n",
    "            missing = set(self.feature_names) - set(X.columns)\n",
    "            for c in missing: X[c] = 0\n",
    "            extra = set(X.columns) - set(self.feature_names)\n",
    "            if extra: X = X.drop(columns=list(extra))\n",
    "            X = X[self.feature_names]\n",
    "            \n",
    "        print(f\"‚úì Predicting with shape: {X.shape}\")\n",
    "        \n",
    "        test_preds = {}\n",
    "        for name in self.models:\n",
    "            preds = []\n",
    "            for model in self.models[name]:\n",
    "                preds.append(model.predict(X))\n",
    "            test_preds[name] = np.mean(preds, axis=0)\n",
    "            \n",
    "        meta_X = pd.DataFrame(test_preds)\n",
    "        return self.meta_model.predict(meta_X)\n",
    "\n",
    "ensemble = UltimateEnsemble(best_params, n_folds=5)\n",
    "ensemble.train_with_cv(X_train, y_train)\n",
    "ensemble.train_meta_learner(y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING FINAL SUBMISSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_log_preds = ensemble.predict(X_test)\n",
    "final_preds = np.expm1(final_log_preds)\n",
    "final_preds = np.maximum(final_preds, 0)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Property_ID': test_ids,\n",
    "    'PREDICTED': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"‚úì Saved {len(submission)} rows to 'submission.csv'\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15183351,
     "sourceId": 126916,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 803.125199,
   "end_time": "2026-01-16T16:16:35.096701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-16T16:03:11.971502",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08da8f7f35b44f2f8d17e46b537b77ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a5358629f89640d988a0f392f51b6065",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_fe2cde14ccbc448fa1ccbba1c531ab23",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá5/5‚Äá[01:21&lt;00:00,‚Äá16.36s/it]"
      }
     },
     "28cb61e79b4048e5a92183ad72df72ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a0ace72788247bb994b541c460292e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56f2df19522d47edbda8d4dc7915a7fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cbd0b809eae54c8ba6b88f8c4207d635",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_810cb87c33f949339ba1a5c67cc0fcc2",
       "tabbable": null,
       "tooltip": null,
       "value": 50.0
      }
     },
     "594d404792f049cd920386f55bfc35d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e711513edb2b46df854864e9fabf2d60",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_777f043c21a14905975ab19db39cc76a",
       "tabbable": null,
       "tooltip": null,
       "value": 5.0
      }
     },
     "5f3a91614f9949bcae4575f1ebc1846e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68b76ea02d924b8fa651fd7cb5eb3439": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6ccdc8dd53004e04b47e4707ec109add": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28cb61e79b4048e5a92183ad72df72ae",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7ad9ff97fe7d4ab6ad8cfdd5ed01e487",
       "tabbable": null,
       "tooltip": null,
       "value": "Folds:‚Äá100%"
      }
     },
     "777f043c21a14905975ab19db39cc76a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7ad9ff97fe7d4ab6ad8cfdd5ed01e487": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7ce8692f3fb040cf8640ce00e75ccb81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "810cb87c33f949339ba1a5c67cc0fcc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8916101619674f899a9e8ac601e1b397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f354ad2a35ae4ef291c6027fa89be394",
        "IPY_MODEL_56f2df19522d47edbda8d4dc7915a7fa",
        "IPY_MODEL_af4a86a3b41344d3a4a68a0b3b1cf95b"
       ],
       "layout": "IPY_MODEL_5f3a91614f9949bcae4575f1ebc1846e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a5358629f89640d988a0f392f51b6065": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af4a86a3b41344d3a4a68a0b3b1cf95b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a0ace72788247bb994b541c460292e3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_fa963748fee24c18a2d3d4658ea170c7",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá50/50‚Äá[11:10&lt;00:00,‚Äá‚Äá9.00s/it]"
      }
     },
     "cbd0b809eae54c8ba6b88f8c4207d635": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de704805b9174651b7c80f70d38cf12f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5218714649449e9ab4c9e99ed28b69c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6ccdc8dd53004e04b47e4707ec109add",
        "IPY_MODEL_594d404792f049cd920386f55bfc35d0",
        "IPY_MODEL_08da8f7f35b44f2f8d17e46b537b77ac"
       ],
       "layout": "IPY_MODEL_de704805b9174651b7c80f70d38cf12f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e711513edb2b46df854864e9fabf2d60": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f354ad2a35ae4ef291c6027fa89be394": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7ce8692f3fb040cf8640ce00e75ccb81",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_68b76ea02d924b8fa651fd7cb5eb3439",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "fa963748fee24c18a2d3d4658ea170c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe2cde14ccbc448fa1ccbba1c531ab23": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
